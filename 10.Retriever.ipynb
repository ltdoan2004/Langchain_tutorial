{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pdf_url = \"https://arxiv.org/pdf/2401.18059v1.pdf\"\n",
    "\n",
    "# PDF loader\n",
    "pdf_loader = PyPDFLoader(pdf_url, extract_images=True)\n",
    "pdf_pages = pdf_loader.load()\n",
    "\n",
    "\n",
    "# Splitter\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "docs = splitter.split_documents(pdf_pages)\n",
    "\n",
    "# Embedding model\n",
    "embedding_model = HuggingFaceEmbeddings()\n",
    "\n",
    "# vector store\n",
    "chroma_db = Chroma.from_documents(docs, embedding=embedding_model)\n",
    "\n",
    "faiss_db = FAISS.from_documents(docs, embedding=embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_K = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Use vector store as a retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_retriever = chroma_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"k\": top_K\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is a RAG system?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = chroma_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='ral Information Processing Systems , volume 33, pp. 1877–1901. Curran Associates, Inc.,\\n10', metadata={'page': 9, 'source': 'https://arxiv.org/pdf/2401.18059v1.pdf'}),\n",
       " Document(page_content='2018), is to index large quantities of text, after splitting it into chunks (paragraphs), in a separate\\ninformation retrieval system. Retrieved information is then presented to the LLM along with the', metadata={'page': 0, 'source': 'https://arxiv.org/pdf/2401.18059v1.pdf'}),\n",
       " Document(page_content='texts of length 100, similar to traditional retrieval augmentation techniques. If a sentence exceeds the\\n100-token limit, we move the entire sentence to the next chunk, rather than cutting it mid-sentence.', metadata={'page': 2, 'source': 'https://arxiv.org/pdf/2401.18059v1.pdf'}),\n",
       " Document(page_content='denses the potentially large volume of retrieved information into a manageable size. We provide\\nstatistics on the compression due to the summarization in Appendix C and the prompt used for\\nsummarization in Appendix D.', metadata={'page': 3, 'source': 'https://arxiv.org/pdf/2401.18059v1.pdf'}),\n",
       " Document(page_content='the information that it retrieves is more relevant and exhaustive, allowing for better performance on\\ndownstream tasks.\\nWe also created a 2600-word story along with questions about its narrative and theme. An excerpt', metadata={'page': 19, 'source': 'https://arxiv.org/pdf/2401.18059v1.pdf'}),\n",
       " Document(page_content='This preserves the contextual and semantic coherence of the text within each chunk. These texts\\nare then embedded using SBERT, a BERT-based encoder ( multi-qa-mpnet-base-cos-v1 )\\n(Reimers & Gurevych, 2019). The chunks and their corresponding SBERT embeddings form the', metadata={'page': 2, 'source': 'https://arxiv.org/pdf/2401.18059v1.pdf'})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_retriever = faiss_db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"k\": top_K\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = chroma_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='ral Information Processing Systems , volume 33, pp. 1877–1901. Curran Associates, Inc.,\\n10', metadata={'page': 9, 'source': 'https://arxiv.org/pdf/2401.18059v1.pdf'}),\n",
       " Document(page_content='2018), is to index large quantities of text, after splitting it into chunks (paragraphs), in a separate\\ninformation retrieval system. Retrieved information is then presented to the LLM along with the', metadata={'page': 0, 'source': 'https://arxiv.org/pdf/2401.18059v1.pdf'}),\n",
       " Document(page_content='texts of length 100, similar to traditional retrieval augmentation techniques. If a sentence exceeds the\\n100-token limit, we move the entire sentence to the next chunk, rather than cutting it mid-sentence.', metadata={'page': 2, 'source': 'https://arxiv.org/pdf/2401.18059v1.pdf'}),\n",
       " Document(page_content='denses the potentially large volume of retrieved information into a manageable size. We provide\\nstatistics on the compression due to the summarization in Appendix C and the prompt used for\\nsummarization in Appendix D.', metadata={'page': 3, 'source': 'https://arxiv.org/pdf/2401.18059v1.pdf'}),\n",
       " Document(page_content='the information that it retrieves is more relevant and exhaustive, allowing for better performance on\\ndownstream tasks.\\nWe also created a 2600-word story along with questions about its narrative and theme. An excerpt', metadata={'page': 19, 'source': 'https://arxiv.org/pdf/2401.18059v1.pdf'}),\n",
       " Document(page_content='This preserves the contextual and semantic coherence of the text within each chunk. These texts\\nare then embedded using SBERT, a BERT-based encoder ( multi-qa-mpnet-base-cos-v1 )\\n(Reimers & Gurevych, 2019). The chunks and their corresponding SBERT embeddings form the', metadata={'page': 2, 'source': 'https://arxiv.org/pdf/2401.18059v1.pdf'})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade --quiet  rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "bm25_retriever.k = top_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = bm25_retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_docs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='text and then mapping the tokens. This amendment improves the accuracy of the METEOR\\ncalculation by taking into account the correct linguistic boundaries of words.\\nQuestion: What is the central theme of the story?', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 20}),\n",
       " Document(page_content='total tokens ←0\\nfornode in top nodes do\\niftotal tokens +node.token size<max tokens then\\nresult.append(node)\\nend if\\ntotal tokens ←total tokens +node.token size\\nend for\\nreturn result\\nend function\\nQuestion: What is the central theme of the story?', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 18}),\n",
       " Document(page_content='LM fine-tuned for open-domain question answering; and RAG (Retrieval-Augmented Genera-\\ntion) (Lewis et al., 2020), which integrates pre-trained sequence-to-sequence models with a neural\\nretriever. Min et al. (2021) introduced Joint Passage Retrieval (JPR) model which uses a tree-', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 1}),\n",
       " Document(page_content='given context, it is not possible to determine how Cinderella finds a happy ending, as the text lacks\\ninformation about the story’s conclusion.”\\nThe second question we examine is “What is the central theme of the story?”, a thematic question', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 19}),\n",
       " Document(page_content='text length increases, especially when pertinent information is embedded within a lengthy context.\\nMoreover, practically, use of long contexts is expensive and slow. This suggests that selecting the\\nmost relevant information for knowledge-intensive tasks is still crucial.', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 1}),\n",
       " Document(page_content='from the story is present below and the full PDF of this story is linked here. For questions like “What\\nis the central theme of the story?”, an upper-level node is retrieved which includes the sentence:\\n“This story is about the power of human connection... inspiring and uplifting each other as they', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 19})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade --quiet  scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import TFIDFRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_retriever = TFIDFRetriever.from_documents(docs)\n",
    "tfidf_retriever.k = top_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = tfidf_retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_docs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='from the story is present below and the full PDF of this story is linked here. For questions like “What\\nis the central theme of the story?”, an upper-level node is retrieved which includes the sentence:\\n“This story is about the power of human connection... inspiring and uplifting each other as they', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 19}),\n",
       " Document(page_content='given context, it is not possible to determine how Cinderella finds a happy ending, as the text lacks\\ninformation about the story’s conclusion.”\\nThe second question we examine is “What is the central theme of the story?”, a thematic question', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 19}),\n",
       " Document(page_content='2018), is to index large quantities of text, after splitting it into chunks (paragraphs), in a separate\\ninformation retrieval system. Retrieved information is then presented to the LLM along with the', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 0}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2024\\nFigure 4: Querying Process: Illustration of how RAPTOR retrieves information for two questions\\nabout the Cinderella story: “What is the central theme of the story?” and “How did Cinderella find', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 6}),\n",
       " Document(page_content='LM fine-tuned for open-domain question answering; and RAG (Retrieval-Augmented Genera-\\ntion) (Lewis et al., 2020), which integrates pre-trained sequence-to-sequence models with a neural\\nretriever. Min et al. (2021) introduced Joint Passage Retrieval (JPR) model which uses a tree-', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 1}),\n",
       " Document(page_content='text and then mapping the tokens. This amendment improves the accuracy of the METEOR\\ncalculation by taking into account the correct linguistic boundaries of words.\\nQuestion: What is the central theme of the story?', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 20})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[chroma_retriever, \n",
    "                faiss_retriever,\n",
    "                bm25_retriever, \n",
    "                tfidf_retriever], \n",
    "    weights=[0.25, 0.25, 0.25, 0.25]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = ensemble_retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='2018), is to index large quantities of text, after splitting it into chunks (paragraphs), in a separate\\ninformation retrieval system. Retrieved information is then presented to the LLM along with the', metadata={'page': 0, 'source': 'https://arxiv.org/pdf/2401.18059v1.pdf'}),\n",
       " Document(page_content='ral Information Processing Systems , volume 33, pp. 1877–1901. Curran Associates, Inc.,\\n10', metadata={'page': 9, 'source': 'https://arxiv.org/pdf/2401.18059v1.pdf'}),\n",
       " Document(page_content='given context, it is not possible to determine how Cinderella finds a happy ending, as the text lacks\\ninformation about the story’s conclusion.”\\nThe second question we examine is “What is the central theme of the story?”, a thematic question', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 19}),\n",
       " Document(page_content='text and then mapping the tokens. This amendment improves the accuracy of the METEOR\\ncalculation by taking into account the correct linguistic boundaries of words.\\nQuestion: What is the central theme of the story?', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 20}),\n",
       " Document(page_content='from the story is present below and the full PDF of this story is linked here. For questions like “What\\nis the central theme of the story?”, an upper-level node is retrieved which includes the sentence:\\n“This story is about the power of human connection... inspiring and uplifting each other as they', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 19}),\n",
       " Document(page_content='texts of length 100, similar to traditional retrieval augmentation techniques. If a sentence exceeds the\\n100-token limit, we move the entire sentence to the next chunk, rather than cutting it mid-sentence.', metadata={'page': 2, 'source': 'https://arxiv.org/pdf/2401.18059v1.pdf'}),\n",
       " Document(page_content='LM fine-tuned for open-domain question answering; and RAG (Retrieval-Augmented Genera-\\ntion) (Lewis et al., 2020), which integrates pre-trained sequence-to-sequence models with a neural\\nretriever. Min et al. (2021) introduced Joint Passage Retrieval (JPR) model which uses a tree-', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 1}),\n",
       " Document(page_content='denses the potentially large volume of retrieved information into a manageable size. We provide\\nstatistics on the compression due to the summarization in Appendix C and the prompt used for\\nsummarization in Appendix D.', metadata={'page': 3, 'source': 'https://arxiv.org/pdf/2401.18059v1.pdf'}),\n",
       " Document(page_content='wal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal,\\nAriel Herbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel\\nZiegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin,', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 9}),\n",
       " Document(page_content='total tokens ←0\\nfornode in top nodes do\\niftotal tokens +node.token size<max tokens then\\nresult.append(node)\\nend if\\ntotal tokens ←total tokens +node.token size\\nend for\\nreturn result\\nend function\\nQuestion: What is the central theme of the story?', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 18}),\n",
       " Document(page_content='Published as a conference paper at ICLR 2024\\nFigure 4: Querying Process: Illustration of how RAPTOR retrieves information for two questions\\nabout the Cinderella story: “What is the central theme of the story?” and “How did Cinderella find', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 6}),\n",
       " Document(page_content='the information that it retrieves is more relevant and exhaustive, allowing for better performance on\\ndownstream tasks.\\nWe also created a 2600-word story along with questions about its narrative and theme. An excerpt', metadata={'page': 19, 'source': 'https://arxiv.org/pdf/2401.18059v1.pdf'}),\n",
       " Document(page_content='matching the question’s detail level. This approach often yields more relevant and comprehensive\\ninformation for downstream tasks than DPR. For a detailed discussion and examples, including the\\ntext retrieved by both RAPTOR and DPR for specific questions, please refer to the appendix G.', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 5}),\n",
       " Document(page_content='text length increases, especially when pertinent information is embedded within a lengthy context.\\nMoreover, practically, use of long contexts is expensive and slow. This suggests that selecting the\\nmost relevant information for knowledge-intensive tasks is still crucial.', metadata={'source': 'https://arxiv.org/pdf/2401.18059v1.pdf', 'page': 1}),\n",
       " Document(page_content='This preserves the contextual and semantic coherence of the text within each chunk. These texts\\nare then embedded using SBERT, a BERT-based encoder ( multi-qa-mpnet-base-cos-v1 )\\n(Reimers & Gurevych, 2019). The chunks and their corresponding SBERT embeddings form the', metadata={'page': 2, 'source': 'https://arxiv.org/pdf/2401.18059v1.pdf'})]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
