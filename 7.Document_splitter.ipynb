{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import requests\n",
    "\n",
    "json_data = requests.get(\"https://api.smith.langchain.com/openapi.json\").json()\n",
    "\n",
    "text_data = \"\"\"\n",
    "Text mining, text data mining (TDM) or text analytics is the process of deriving high-quality information from text. \n",
    "It involves \"the discovery by computer of new, previously unknown information, by automatically extracting information from different written resources.\"\n",
    "[1] Written resources may include websites, books, emails, reviews, and articles. \n",
    "High-quality information is typically obtained by devising patterns and trends by means such as statistical pattern learning. \n",
    "According to Hotho et al. (2005) we can distinguish between three different perspectives of text mining: information extraction, data mining, \n",
    "and a knowledge discovery in databases (KDD) process.\n",
    "[2] Text mining usually involves the process of structuring the input text (usually parsing, \n",
    "along with the addition of some derived linguistic features and the removal of others, \n",
    "and subsequent insertion into a database), deriving patterns within the structured data, and finally evaluation and interpretation of the output. \n",
    "'High quality' in text mining usually refers to some combination of relevance, novelty, and interest. \n",
    "Typical text mining tasks include text categorization, text clustering, concept/entity extraction, \n",
    "production of granular taxonomies, sentiment analysis, document summarization, and entity relation modeling (i.e., learning relations between named entities).\n",
    "\"\"\"\n",
    "\n",
    "markdown_data = \"# Foo\\n\\n    ## Bar\\n\\nHi this is Jim\\n\\nHi this is Joe\\n\\n ### Boo \\n\\n Hi this is Lance \\n\\n ## Baz\\n\\n Hi this is Molly\"\n",
    "\n",
    "html_data = \"\"\"\n",
    "\n",
    "<h2 id=\"data\">Data</h2>\n",
    "\n",
    "<p>I searched GitHub using the keywords <code class=\"language-plaintext highlighter-rouge\">gpt</code>, <code class=\"language-plaintext highlighter-rouge\">llm</code>, and <code class=\"language-plaintext highlighter-rouge\">generative ai</code>. If AI feels so overwhelming right now, it’s because it is. There are 118K results for <code class=\"language-plaintext highlighter-rouge\">gpt</code> alone.</p>\n",
    "\n",
    "<p>To make my life easier, I limited my search to the repos with at least 500 stars. There were 590 results for <code class=\"language-plaintext highlighter-rouge\">llm</code>, 531 for <code class=\"language-plaintext highlighter-rouge\">gpt</code>, and 38 for <code class=\"language-plaintext highlighter-rouge\">generative ai</code>. I also occasionally checked GitHub trending and social media for new repos.</p>\n",
    "\n",
    "<p>After MANY hours, I found 896 repos. Of these, 51 are tutorials (e.g. <a href=\"https://github.com/dair-ai/Prompt-Engineering-Guide\">dair-ai/Prompt-Engineering-Guide</a>) and aggregated lists (e.g. <a href=\"https://github.com/f/awesome-chatgpt-prompts\">f/awesome-chatgpt-prompts</a>). While these tutorials and lists are helpful, I’m more interested in software. I still include them in the final list, but the analysis is done with the 845 software repositories.</p>\n",
    "\n",
    "<p>It was a painful but rewarding process. It gave me a much better understanding of what people are working on, how incredibly collaborative the open source community is, and just how much China’s open source ecosystem diverges from the Western one.</p>\n",
    "\n",
    "<h3 id=\"add_missing_repos\">Add missing repos</h3>\n",
    "\n",
    "<p>I undoubtedly missed a ton of repos. You can submit the missing repos <a href=\"https://forms.gle/1ijNSnizgWQaVYK16\">here</a>. The list will be automatically updated every day.</p>\n",
    "\n",
    "<p>Feel free to submit the repos with less than 500 stars. I’ll continue tracking them and add them to the list when they reach 500 stars!</p>\n",
    "\n",
    "<h2 id=\"the_new_ai_stack\">The New AI Stack</h2>\n",
    "\n",
    "<p>I think of the AI stack as consisting of 4 layers: infrastructure, model development, application development, and applications.</p>\n",
    "\n",
    "<center>\n",
    "    <figure>\n",
    "    <img alt=\"Generative AI Stack\" src=\"/assets/pics/ai-oss/1-ai-stack.png\" style=\"float: center; max-width: 100%; margin: 0 0 0em 0em\" />\n",
    "    </figure>\n",
    "</center>\n",
    "<p><br /></p>\n",
    "\n",
    "<ol>\n",
    "  <li>\n",
    "    <p><strong>Infrastructure</strong></p>\n",
    "\n",
    "    <p>At the bottom is the stack is infrastructure, which includes toolings for serving (<a href=\"https://github.com/vllm-project/vllm\">vllm</a>, <a href=\"https://github.com/triton-inference-server/server\">NVIDIA’s Triton</a>), compute management (<a href=\"https://github.com/skypilot-org/skypilot\">skypilot</a>), vector search and database (<a href=\"https://github.com/facebookresearch/faiss\">faiss</a>, <a href=\"https://milvus.io/\">milvus</a>, <a href=\"https://github.com/qdrant/qdrant\">qdrant</a>, <a href=\"https://github.com/lancedb/lancedb\">lancedb</a>), ….</p>\n",
    "  </li>\n",
    "  <li>\n",
    "    <p><strong>Model development</strong></p>\n",
    "\n",
    "    <p>This layer provides toolings for developing models, including frameworks for modeling &amp; training (transformers, pytorch, DeepSpeed), inference optimization (ggml, openai/triton), dataset engineering, evaluation, ….. Anything that involves changing a model’s weights happens in this layer, including finetuning.</p>\n",
    "  </li>\n",
    "  <li>\n",
    "    <p><strong>Application development</strong>\n",
    " With readily available models, anyone can develop applications on top of them. This is the layer that has seen the most actions in the last 2 years and is still rapidly evolving. This layer is also known as AI engineering.</p>\n",
    "\n",
    "    <p>Application development involves prompt engineering, RAG, AI interface, …</p>\n",
    "  </li>\n",
    "  <li>\n",
    "    <p><strong>Applications</strong></p>\n",
    "\n",
    "    <p>There are many open sourced applications built on top of existing models. The most popular types of applications are coding, workflow automation, information aggregation, …</p>\n",
    "  </li>\n",
    "</ol>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "code_data = \"\"\"\n",
    "def sample_top_p(probs: torch.Tensor, p: float):\n",
    "    assert 0 <= p <= 1\n",
    "\n",
    "    probs_sort, probs_idx = torch.sort(probs, dim=-1, descending=True)\n",
    "    probs_sum = torch.cumsum(probs_sort, dim=-1)\n",
    "    mask = probs_sum - probs_sort > p\n",
    "    probs_sort[mask] = 0.0\n",
    "    probs_sort.div_(probs_sort.sum(dim=-1, keepdim=True))\n",
    "    next_token = torch.multinomial(probs_sort, num_samples=1)\n",
    "    return torch.gather(probs_idx, -1, next_token)\n",
    "\n",
    "\n",
    "def sample(logits: torch.Tensor, temperature: float, top_p: float):\n",
    "    if temperature > 0:\n",
    "        probs = torch.softmax(logits / temperature, dim=-1)\n",
    "        next_token = sample_top_p(probs, top_p)\n",
    "    else:\n",
    "        next_token = torch.argmax(logits, dim=-1).unsqueeze(0)\n",
    "\n",
    "    return next_token.reshape(-1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Character Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 300\n",
    "chunk_overlap = 30\n",
    "separators: List[str] = ['\\n\\n', '\\n', ' ', '']\n",
    "\n",
    "char_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    "    separators=separators\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Split text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_out = char_splitter.split_text(text_data)\n",
    "len(text_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Text mining, text data mining (TDM) or text analytics is the process of deriving high-quality information from text. \\nIt involves \"the discovery by computer of new, previously unknown information, by automatically extracting information from different written resources.\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_out[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Create documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = char_splitter.create_documents(text_out)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Text mining, text data mining (TDM) or text analytics is the process of deriving high-quality information from text. \\nIt involves \"the discovery by computer of new, previously unknown information, by automatically extracting information from different written resources.\"'),\n",
       " Document(page_content='[1] Written resources may include websites, books, emails, reviews, and articles. \\nHigh-quality information is typically obtained by devising patterns and trends by means such as statistical pattern learning.'),\n",
       " Document(page_content='According to Hotho et al. (2005) we can distinguish between three different perspectives of text mining: information extraction, data mining, \\nand a knowledge discovery in databases (KDD) process.\\n[2] Text mining usually involves the process of structuring the input text (usually parsing,'),\n",
       " Document(page_content='along with the addition of some derived linguistic features and the removal of others, \\nand subsequent insertion into a database), deriving patterns within the structured data, and finally evaluation and interpretation of the output.'),\n",
       " Document(page_content=\"'High quality' in text mining usually refers to some combination of relevance, novelty, and interest. \\nTypical text mining tasks include text categorization, text clustering, concept/entity extraction,\"),\n",
       " Document(page_content='production of granular taxonomies, sentiment analysis, document summarization, and entity relation modeling (i.e., learning relations between named entities).')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Split Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "small_docs = small_splitter.split_documents(docs)\n",
    "len(small_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='def sample_top_p(probs: torch.Tensor, p: float):')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. JSON Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveJsonSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_chunk_size = 300\n",
    "json_splitter = RecursiveJsonSplitter(max_chunk_size=max_chunk_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Split json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1139"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_out = json_splitter.split_json(json_data)\n",
    "len(json_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'openapi': '3.1.0',\n",
       " 'info': {'title': 'LangSmith', 'version': '0.1.0'},\n",
       " 'servers': [{'url': 'https://api.smith.langchain.com',\n",
       "   'description': 'LangSmith API endpoint.'}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_out[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Split as text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2277"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_out = json_splitter.split_text(json_data)\n",
    "len(text_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"openapi\": \"3.1.0\", \"info\": {\"title\": \"LangSmith\", \"version\": \"0.1.0\"}, \"servers\": [{\"url\": \"https://api.smith.langchain.com\", \"description\": \"LangSmith API endpoint.\"}]}'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_out[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Create documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3415"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = json_splitter.create_documents(texts=[json_data])\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='{\"openapi\": \"3.1.0\", \"info\": {\"title\": \"LangSmith\", \"version\": \"0.1.0\"}, \"servers\": [{\"url\": \"https://api.smith.langchain.com\", \"description\": \"LangSmith API endpoint.\"}]}')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"openapi\": \"3.1.0\", \"info\": {\"title\": \"LangSmith\", \"version\": \"0.1.0\"}, \"servers\": [{\"url\": \"https://api.smith.langchain.com\", \"description\": \"LangSmith API endpoint.\"}]}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Markdown Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on: List[tuple] = [(\"#\", \"Header 1\"),\n",
    "                                    (\"##\", \"Header 2\"),\n",
    "                                    (\"###\", \"Header 3\"),]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = markdown_splitter.split_text(text=markdown_data)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Hi this is Jim  \\nHi this is Joe', metadata={'Header 1': 'Foo', 'Header 2': 'Bar'})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. HTML Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import HTMLHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on: List[Tuple[str, str]] = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "]\n",
    "html_splitter = HTMLHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = html_splitter.split_text(text=html_data)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='I searched GitHub using the keywords gpt, llm, and generative ai. If AI feels so overwhelming right now, it’s because it is. There are 118K results for gpt alone.  \\nTo make my life easier, I limited my search to the repos with at least 500 stars. There were 590 results for llm, 531 for gpt, and 38 for generative ai. I also occasionally checked GitHub trending and social media for new repos.  \\nAfter MANY hours, I found 896 repos. Of these, 51 are tutorials (e.g. dair-ai/Prompt-Engineering-Guide) and aggregated lists (e.g. f/awesome-chatgpt-prompts). While these tutorials and lists are helpful, I’m more interested in software. I still include them in the final list, but the analysis is done with the 845 software repositories.  \\nIt was a painful but rewarding process. It gave me a much better understanding of what people are working on, how incredibly collaborative the open source community is, and just how much China’s open source ecosystem diverges from the Western one.', metadata={'Header 2': 'Data'})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Code Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cpp': <Language.CPP: 'cpp'>,\n",
       " 'go': <Language.GO: 'go'>,\n",
       " 'java': <Language.JAVA: 'java'>,\n",
       " 'kotlin': <Language.KOTLIN: 'kotlin'>,\n",
       " 'js': <Language.JS: 'js'>,\n",
       " 'ts': <Language.TS: 'ts'>,\n",
       " 'php': <Language.PHP: 'php'>,\n",
       " 'proto': <Language.PROTO: 'proto'>,\n",
       " 'python': <Language.PYTHON: 'python'>,\n",
       " 'rst': <Language.RST: 'rst'>,\n",
       " 'ruby': <Language.RUBY: 'ruby'>,\n",
       " 'rust': <Language.RUST: 'rust'>,\n",
       " 'scala': <Language.SCALA: 'scala'>,\n",
       " 'swift': <Language.SWIFT: 'swift'>,\n",
       " 'markdown': <Language.MARKDOWN: 'markdown'>,\n",
       " 'latex': <Language.LATEX: 'latex'>,\n",
       " 'html': <Language.HTML: 'html'>,\n",
       " 'sol': <Language.SOL: 'sol'>,\n",
       " 'csharp': <Language.CSHARP: 'csharp'>,\n",
       " 'cobol': <Language.COBOL: 'cobol'>,\n",
       " 'c': <Language.C: 'c'>,\n",
       " 'lua': <Language.LUA: 'lua'>,\n",
       " 'perl': <Language.PERL: 'perl'>}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langaue_dict = {e.value: e for e in Language}\n",
    "langaue_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 300\n",
    "chunk_overlap = 30\n",
    "\n",
    "code_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language = langaue_dict[\"python\"],\n",
    "    chunk_size = chunk_size,\n",
    "    chunk_overlap = chunk_overlap\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = code_splitter.create_documents(texts=[code_data])\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='def sample_top_p(probs: torch.Tensor, p: float):\\n    assert 0 <= p <= 1')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "online_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
